 So, let's talk about automating ACI with Python and the corporate SDK. And if you haven't attended a previous webinar by me before or haven't been in one of these PIWs, my name is Marcel. I'm a software solutions engineer for EMEA Systems Engineering. That means that I have the opportunity to work with our large partners and with our large customers on anything related to programmability, focusing in the past few years mainly on automating and network side of things. But today, we're talking about ACI and the corporate SDK. And before diving right into the code, right before going into the technical bits and showing you how you can connect to the API and doing all of these things, and at the end, we'll also see a few interesting use cases that have been built using the API. Let's start with why, right? Let's start thinking about why we would want to automate something like our APIC, why we want to automate processes in that part. And like, if you do a survey on this and if you ask people like, hey, what, why do you want to do that? Right? Some of the things that come up is cost reduction. Of course, everyone has OPEX constraints. So we might want to be able to reduce the time it takes, reduce the cost associated with certain workflows, simplicity, right? Like it's a lot simpler to just kick off a script and kick off an automation than having to maybe configure a lot of things inside of the APIC. Right? So consistent configuration is also something, right? Like if you're just, you know, giving you a switching example, but if you just have someone SSH to a switch and do some things, configure some stuff, you will eventually get to a system where you might have an understanding, maybe in a SharePoint page or whatever, what your configuration is or what you believe your configuration is. And then you have the is state, which is quite often very disjunct, right? Like where people have drifted the configuration away from the actual configuration. So you have to be able to get the information out of the configuration and then you have to figure out how to get it out of the configuration. So you have to be able to get the information out of the configuration. So you have to be able to get the information out of the configuration. Reducing time consuming repetitive tasks, right? This is the whole point of automation that we automate the boring stuff so that we can spend more time on the actually interesting stuff like infrastructure, like architecture, these kinds of things. Right? The stuff that's actually interesting and that actually propels forward. Right? Finally getting around to building that new service that you wanted to do. Scaling, right? If you have written a script once, you can do it again. And reduce maintenance window. So these are like the top reasons that usually get given for automation. And these reasons are, I didn't write data center automation on top there, right? These are fairly common that you will encounter them in pretty much every automation related stuff from IT automation to automating your factory, right? Everything is going to be for that reasons. Data centers in particular have one more reason. And that reason is. The cloud, right? We care about automation because we have 2 different personas roughly, and there's a few more, but we have different personas acting in our data center, right? We have the infrastructure engineers, the people that care about routing the people that care about the security, the people that care about. If we're talking about specifically, and these kinds of infrastructure related topics, right? Making sure that your infrastructure works and making sure that your infrastructure is working. That everything runs run smoothly. And then you have the people actually using your infrastructure, right? Could be software developers could be application teams. But you have people that. They, they are not that interested in the infrastructure. They just want to consume that infrastructure, right? And software engineers in particular, they will be talking or they will be caring about deployments, right? They will be talking about their time to market. They want to optimize that. They want to talk about quick access to resources, right? They don't want to go through an approval process. And wait. For a long, long time. In order to get some sort of new server for the lab environment set up, or to get some access rules changed so that they can run their run their software. So these, these, these two groups. Not only have different. Perceptions of what infrastructure is right for some of them. It is all the interesting technical topics and the it's like their day-to-day job. And for others, it's a resource, right? They also have different incentives, right? The infrastructure engineers. Are hard challenged when the infrastructure goes down. Right? If your data center crashes, it's you at 2 AM in the morning doing work and having to restore all of that. While the software developers usually more care about their velocity into the market, right? They are getting paid. The more features they ship. And they are getting the bonus for that great feature that they ship that is winning over the world by storm. So they are more inclined to sacrifice stability for improving, for improving the technology. And they are more inclined to say, hey, let's do this. We are going to change velocity while your infrastructure engineers usually are more inclined to say, hey, calm down. Let's let's stop. Let's let's really test all of this out before we do any changes. And, and this, this like dichotomy, right? Like this, this problem here is, is really what's at the heart of this. And I already mentioned this, the word, right? Like the thing why developers really, really like the cloud is. Not necessarily because they don't like data centers. But because the cloud is more convenient for all of these aspects that we just talked about. Right? The cloud in their perception is cheaper. Even if that's sometimes not the case. The cloud is quicker. Like spinning up a new instance in the cloud. Sometimes it's clicking one button and or issuing one command on, on, on some CLI and you get a full VM spun up. And more importantly, they can control the cloud. Right? They, they, they understand how they can deal with, with the cloud providers and how they can get the resources that they want to have. And the, the, the speed of access. And the, the, the speed of access that they, they are expecting from, from the cloud. Now, if you, if you then think about the infrastructure engineers, hey, how can we get rid of these processes? How can we make the DC more, more cloud-like? How can we make sure that we can adopt to that, that velocity that a, that a software developer these days is expecting? And I mean, there is, there is two different ways out of this, right? You could go out and say you, we, we're staffing up, right? We're going to have a thousand ACI engineers. Right? We're going to have a thousand data center engineers that are constantly on call and twiddling their thumbs for 90% of the time waiting for that one ticket to come in from the, from the, from developers. And then we have a team of 15 engineers rushing out that change in order to, to make it, make it an almost instant experience. The problem is you guys, you ACI experts are really, really rare in the world, in the job market. So staffing up to a thousand ACI experts, you probably build a monopole on, on that experience. And you're still probably wouldn't be as fast as if you were automating the processes, right? Automating certain things that your developers need from you or certain things that your infrastructure consumers need from you in order to be faster in these, in these, in these aspects. And that is, that is what we're going to look at today, right? Like how you can use tools like corporate, or you can use tools like the, like the API to streamline your processes such that you can accommodate the needs of your customers. And you can also make these, these changing velocities and also make your life maybe a bit easier by, by doing that. And as I said already in the end, after the, after the technical stuff, we'll also have a look at three different use cases just to show you what you can do with these, with these tools that you are, that you are seeing with the API and with these, with these different possibilities. So let's quickly summarize three different words that I'm going to be using today. I assume that if you're joining this webinar today, you're going to be using the word, the word, the word, the word, the word. And I'm not going to give you a good explanation of that. And you know, you have a, a bit of knowledge of ACI. So I'm not going to give you any, any like explanation of ACI itself. You probably know even a bit more than I do about that. So we have the classes, right? Like the tenants. We have our managed objects that we are performing operations on, like getting details or changing. And then we have these distinguished names of the managed objects that you will see in some, in, in some of our, in some of our examples. So let's interact with the APIC REST API using Python. Let's have a look at how we can do that. And at first I know that the presentation is titled Cobra SDK, but let's do it the old way without any SDK, without any tools, right? Through it bare bones. And then we'll also see why we would want to have those tools, right? So the first thing I have to do when I'm interacting with the APIC, and I'm going to be interacting with a always on sandbox here. This is the sandbox API, apicdc.cisco.com. So you can find that in our definite sandboxes. It's an always on shared thing. I think it's running the APIC simulator. All right, it's not a real APIC, but it's the simulator. But you see, we have like all the different stuff, like the tenants and all of these different things that we can click around and that we can see here in the system, the fabric, networking, admin operations, all the things that you know from the ACI. So let's start with the authentication, right? We do need to get a way of authenticating ourself to the APIC. And the way that the APIC is running, the way that this is done here in the ACI API is that we need to send a request with our username password combination to a authentication endpoint. And that authentication endpoint then will give us a session cookie that we need to set on every subsequent, every subsequent request to the actual API that we want to do, right? Like we log in using username password, and then afterwards we use that session cookie that gets set for all of our applications. So we can see that we have all the subsequent requests. Now for the path, for the interaction itself, right? We're going to use the requests package, which is a nice open source package written in Python that allows you to do web requests. I think they are the catch line is web requests, the human way. So they allow you to do web requests in a more convenient, more easy way than if you had to have to use things like URL lib, things like that. So we can, first off import the requests, import that request package. And I already said that I will deal with cookies. And while we can, when we do our requests with requests, we can extract the cookies that we get from something. It is much more convenient to use what's called a session. So the session will store things like headers or also cookies between different requests. So that means that we just need to do a authentication request once with our session. And as long as we use the same session object for all of our subsequent requests to the rest API, we can, we don't have to worry about that cookie. So let's first define our base URL. As I said, this is the definite sandbox. So this is sandbox, should copy it over. This is this link. Going to strip that away when I'm going to already add the API sub path. So everything related to the API is under slash API. And then I can build myself, my login URL, which is going to be using the format string here, which is going to be the base URL. And then it is slash AA login. Now, one part about the API from theisc when the the ACI API is that you can get all the responses as well as you can send your requests with two different formats data formats. You can either use Jason payloads or you can use XML payloads. and how you determine which response you're getting or what response or what request format or body format the API is expecting from you is by using these .json or .xml. I'm going to use throughout this example, I'm only going to use JSON simply because I personally do prefer JSON a lot more. But in theory, if you feel more comfortable with XML, you could also do this in XML. So we have a login URL. We now need the payload that we want to send to this login URL. And then we will need to set up that session that I talked about before. So let's start with the session. I'm just going to call this S. You can call this whatever you want, really. And this is now just from the request creating a new session object. And you might've seen like header updates in previous stuff. We don't need to do that because as I said, the authentication works via that cookie and that cookie is going to be saved for us anyway. So we also need the, sorry, let me close that. Okay, we also need the payload. So that payload looks like this and you can find the structure of the payloads if you're going into the API documentation. So you have attributes and then you have the name. This is your username. In this case, this is admin and you have the password property or the password attributes. So you have the password attribute which is the password of the login. I'm going to go over and copy this. As I said, this is always on sandbox. So you can use this if you want to, right? Like this cryptic string. So this is the payload that we want to send. And that means that we can now go ahead and say response is equals to session.host. We're always posting here and we're going to post that to the login URL and we're going to send it to the login URL. We want to send a JSON payload, right? This is where if you would do XML, you could do an XML thing here, but we want to use a JSON payload. This JSON payload, we're sending JSON. So let me print rasp.statuscode and also let me, yeah, let me print the rasp.statuscode and let me print my code. So auto-completion just a little bit. Let me print the rasp.cookies. So I'm getting a verification error. This is because we're using an unverified certification. So I'm just adding a verify false flag. And you see that we are getting this 200 here. So the request was successful. And then we also get, here, the cookie jar object, which is the name for the cookie container. And you see cookie, apic cookie equals, and then this JSON web token, which is our authentication token. So with that done, we are now authenticated. And as I said, every request that we're doing using this session is now going to be authenticated. So let's do another request. And in this case, we do want to get a self, a list of our tenants. So I'm going to query slash classes because I want to list off all of them. And then every tenant dot JSON. Again, I'm going to set our verification to false. And I'm going to once again, do r.statuscode. And I'm going to go and say r.json. I'm going to print out the JSON response that I get from the apic. You see, we got a very unruly piece of, of JSON. So let's quickly format that a bit nicer. Importing JSON here. And then I'm just going to dump out JSON again. You could also use something like pretty print. If you, if you prefer that, personally, always do it like this. And there we go. There we have all of our tenant objects, all of our stuff that we wanted to get from the API, right? The DN, all the information that are available via the API that are also available via the web interface. And with that, with that, we can also do more advanced workflows. Like for example, specifying a filter, right? Like we can create a filters object here. And the name of that is very target filter. And we can do something like, an equality filter. In this case, I want to do every tenant.name. And I want that to be equal to search for a name here in the tenants. There's a CSV that was configured by Ansible, according to the description. But I can do that here, right? Like the tenant name should be equal to CSV. And now I can pass on this filter as a URL parameter. And then I can, like this. The benefit of passing it as a params, it's like creating it as a dictionary and passing it on as a param is that requests, the request library will take care of the URL safe and coding and all of these kinds of things for you, which especially with a bit more involved stuff, like you have, yeah, you have like brackets and all of these kinds of things in these, in these filters can be, can be, can be more beneficial, like, so that I would always recommend you pass filters and URL parameters like this. So we can rerun this and you can see, we now have a total count of one and we have only that tenant that we filtered. So the, the ACI API, as you can see from, from these few examples, and we are just querying stuff here is, is not creating stuff like that. You will see that in a second. It is very powerful. But at the same time, it is also fairly, it is also fairly complex, right? It's not, it's not like very easy to do, right? Like the, the, what, what kind of payloads you need to specify, what kind of stuff you need to specify is, is a bit, it's a bit like not, not, not intuitive, I would say. In, in it, it doesn't make sense, right? It's, it's, it's according to the object model that is within the ACI. So if you know that object model, you probably know what, what kind of properties you need to set, but still it is, we are, we are still dealing with, you know, like we see here with the, with passing and then passing adjacent requests. And we need to deal with error handling and we need to deal with a lot of stuff that while, while being, while being important is not, is really repetitive and doesn't have anything to do with our ultimate goal, which was to streamline a process and make our process easier, right? So we want to introduce more process in order to strip away other process. It's not really what you want. And this is exactly where the Cobra SDK comes into play, right? The idea behind the Cobra SDK is that we are now abstracting away the, the stuff that, that needs to be done all the time, like logging in, making sure that your session cookie is set, making sure that all of the stuff is properly done and also parsing those, those responses that you saw, right? So that we can actually get the data that we got from our, from back from our ACI parsing that into a Python object, right? So that instead of having to do that, what we saw, what we did here with the, with the, with the, we see here instead of getting like an IM data and then getting like a list of, of Jason stuff and the attributes and all of this kind of stuff and having to, having to parse it and having to deal with that, just being able to say, yeah, tenant dot name or tenant dot description in a, in a more Pythonic way than we might be having it. If we're dealing with raw, with raw Jason, with raw Jason responses and does, if we're running that in, in, in Python with, with dictionaries before I go into the Cobra SDK, is there any questions? There's a question that asks, how about signature based authentication as a documentation recommends for this method? Yeah, you can, you can also do that with, with, with Cobra. I can add a link to how you can do that with the slides for convenience. In this example, I did it. I'm using the username password way, but you can also do signature based. And I will. Fantastic. Thank you. There's another question asking who produces and maintains the Cobra SDK. So this is done by the business unit. So this is, you can find it. It's a library is, is available there. The code for the library is available on, on GitHub. It's I think it's a GitHub slash data center or Cisco data center, something like that. I will, I'll have to link in the, in the presentation at the end. And it is produced there, but we'll, we'll talk about how you can install this SDK, which is not, not, not as convenient as with some other libraries in a second, but it's the mapping. Is, is done using. Yeah, it's done by the, by the BU. And the idea is we're going a bit into Cobra now already, but the idea with Cobra is that you have a one-to-one mapping between the models that are in your, in your ACI and the models that are available within Cobra. Fantastic. And one more question that was in the chat with instead of the Q and A, that is how do you compare REST API tools like Postman to Cobra SDK? That's a, that's an excellent question. You, you saw me, I, I popped up my Postman, like I have it open right here. The way that I would see this is that I always like to use Postman to test out things, right. To, to explore a bit, like how do the, how do the, how do the end points look like? What do I get back? What do I need to send? Like, what are the errors? Just because for that, I feel like Postman is really, really convenient for, for like proper automation workflows. I would always go to, to something like something like Cobra or like writing it as a proper script, A, because it's much easier to just run a Python script instead of doing like a, you know, a sequence of, of requests in your Postman collection and B because Cobra has some features like, like validation and it has some features like checking. And as I said, like that, that mapping of being able to map Jason directly into a Python object that you can then use, use going forward. So, so for exploring Postman is great. And I, I, I have it open, right? I use it all the time. It's one of the few tools that auto start with the start of my computer and pretty much never close. But for, for proper automation for the workflows, I would always go with something like with something like a Python script. Now, if you want to compare Python to something like Ansible, that's, that's personal preference, really. That's, that's about what you are feel more comfortable with using. And we'll see that in the use case is one of those examples. It's built using Ansible instead of Python. And really it's a tool that you are using to interact with the API in a programmatic way. And if you feel more comfortable with something like Ansible, go with that. If you feel more comfortable with Python, go with Python. But yeah, Postman, I would say for exploring, for understanding how does the API behave? How do I do things like trying out stuff like that? A couple more questions coming in. One of them is CCDs. Is Cobra something that you can buy or is it free to use? Cobra is available on your APIC. So we are going to see that in the, in the next slide. So in order to install, you cannot do pip install Cobra or something like that. You will have to download it from your APIC. The link is up there, right? It's your APIC URL slash download slash underscore Cobra. I also have the link to the getting started guide at the end in the, in the useful links section. If you would want to play around with it, you can, you can probably maybe know that there's the ACI simulator, which we are also running against here in this, in this sandbox example. And the Cobra is Cobra is not part of the ACI simulator, but I have included a link there for our Cisco definite stuff where for the learning labs, they have uploaded a version of the, of the, of the wheel files that you can use to install Cobra. But Cobra itself is included with your APIC. You don't need to pay for that. Okay. And the last one before you can move on, comparing Cobra, Cobra versus the ACI toolkit and versus Terraform, you know, which one has more functionality, which one, you know, do you consider best? Best is the best is always personal from, from a feature completeness point of view, as far as I know, Cobra is more feature completed models, more of the end points and it models more of the, more of the ACI models than the ACI toolkit does. But if you can get your, your stuff done with the ACI toolkit, you can also use the ACI toolkit. Terraform is just another tool, right? That's, that's then the choice of your tooling and also a bit like the choice of what are you already using, right? If you are, you have an entire network automation stack built in Terraform, makes sense to use Terraform going forward to do it with your, to use that, right? If you have something with Ansible, you can use Ansible. And in fact, we did a webinar last year on automating with Ansible. So, it's, it's really then personal choice, but for the, for the two Python packages, as far as I know, the Cobra package is more feature complete than the, than the ACI toolkit. Very cool. Many thanks, Rochelle. Okay. So I already answered it, or I already covered this slide with the installation of the Cobra file, right? You can, if you want to play around with it, also using the ACI simulator, the way that I am doing it now, you can install it from that, from that link that I provided there. Which is also the link to some learning labs. If after the session you want to do them, do like a, like a step-by-step guided learning lab. You can, you can follow that, follow that link. And as I said, I will have that in the, in the useful links at the end of the presentation. So let's, let's use Cobra and let's re rebuild the workflow that we had here, right? Like what we, what we're seeing here. So this is, this was my auto completion, the workflow that we had here and let's rebuild that in Cobra. Okay. So let's, And so you see, I have my two Cobra files here. I've already installed them in my virtual environment. And now I can go ahead and say, Cobra. Yeah, right. Whatever I'm going to call this, this script. And I can go ahead and first off install from Cobra dot. MIT dot access. Or MIT dot access. Import MO directory. This is just my modeled objects directory. This is like my, my high level object that I'm going to use in order to deal with the, with the APIC. And then I also need to import the. Minimize this import my login session. But this is where I'm going to be providing the login credentials. And I'm going to go ahead and specify my APIC URL, just to make it. Convenient. In this case, I don't have to, like I did with my requests. I don't have to. I don't have to specify. That I want to want to be on the slash API path, right? Cobra understands what, what our house looked like. And then I'm going to create a login session. Login session type. That's the first off the. First off the APIC URL, the user and the password. And you can also see, by the way, the request format here is XML. So they, the Cobra SDK itself uses XML. We don't really care about that because we are not going to touch a single line of XML because that has been abstracted for us. But I can go ahead and pass the username and password, which again, use admin user and as password, I'm going to use the same one. That was here. This one. All right. And then I can. I can. I can create myself the high level object. And I'm going to have to pass it a login session. And then I can do a dear dot. Login. And I can also do a mod or dot a lockout. Right? So what I'm doing right now is I'm logging into the session, which is in the background. It's fetching all of these information, like log and cookie and all of these things. I'm getting it. So you see no errors. I'm just adding something new here. Except for this warning. Which is. We're. We're skipping the certificate and clarification. And we can. Disabled is postponing. This is a requests. Warning. We can disable it. By. Following in for requests. And I'm just adding to see the warning. It doesn't really do anything. But. it gets a bit annoying from time to time. URL read out this little, I think this is fine. Should be the correct one, yeah. Well, I'm rerunning this now, I'm not getting that warning. And as I said, it's just a warning because we are ignoring the verification of the certificate, but we can disable this now. Okay, but now we have our directory, we have it locked in. So now we can go ahead and get our tenants. So I can say tenants is equal to modir. So this is the object that I'm dealing with, that I'm accessing all the stuff by, and I can do lookup by, and I could either do a lookup by a distinguished name, or in my case, I wanna do a lookup by class. And the class that I wanna look up is FV tenant. And then I can just iterate over this, right? I can say for tenant in tenants, print, I'm going to use format strings again, tenant.dn colon tenant. Let's do name, right? Something like that. And then afterwards we are logging out again. Can run this, take some time. Now you see here, I have the response back from the API. Right, I have here the tenant 392, 393, and 394, for example, and that's their name. And that is their UN. And you can probably already see like the difference between this and this, right? This is much more convenient to do, right? Much more convenient to use, especially because as I said, I'm dealing here with like Python objects that I can just do, you would tnt.dn or tenant.dn, tenant.name, these kinds of things. So it's, yeah, in that indirect way, a lot more convenient. Now, what we also saw was the, what we also saw was the filtering in our previous example, right, where we did that URL filtering. And we can also do that here. And we can do that by going cobra.mit.request import, and then we can also do that by doing a query. So in the last query, I'm always looking at the documentation because these imports sometimes are hard to remember. And what I wanna do now is I wanna do a look up on tenants. So I do have to specify our query. So I'm calling this tnQuery for tenant query. And again, you can call this however you want. And this is a class query. So the basis is every tenant, right? So I'm doing it. I'm gonna do a query on our class, on our tenant class, and then I can set a prop filter. So this is the property filter. That's the same that we had previously, right? The same one that we saw here. And that is going to be equals fvtenant.name, and then csv, for example. This is one of the names that we have in here, right? If I guess correctly, yeah. So I can just set the csv. That's the one that we already worried for in the previous example. And I can just set that here, the prop filter in that way. And now here, instead of doing this look up by class, which is going to give me all of the classes, and you can also, by the way, pass a query filter in that class, but I wanted to show you the object way. I can now go ahead and I can do modir.query. So this is going to accept the object. I can now add a query object, which in this case we called tnQuery. And we're going to get this response. So you can run that and you see now, I only have queried this to this one. So this is how you can filter your objects or how you can do filters on your objects. Again, here as well, in my opinion, in a much more convenient way than if we do this in like the pure rest way. So this is how you can filter your objects. so to speak. Now, one thing that I conveniently skipped in the rest API and the pure rest and the request way of doing this was the creation of a tenant, for example, or the creation of any object, simply because that can be a bit of an unruly thing, especially with the way that we have to do the payloads that we have to send. And in Cobra, this is much easier because, as I said, before we have that model, right? We have these Python models that I'm also using here to do this tnt.dnlookup or tnt.name, right? We have that model. So we have objects that we can deal with instead of having to deal with payloads as itself. So let's have a look at Cobra create.py, right? And I'm just copying the stuff here, the login, all of this is going to be the same, of course. And the meet now happens here. Also, because we can now have a look at how we deal with these nested objects, right? With, for example, an app profile that is, that is an application profile that is associated with a new tenant. And the way we can do this, or the way that Cobra handles this is with the aforementioned models, and we need to import them. So we can say from Cobra.model.fv, import tenant and AP. I also now need, my uni object, this one here, and I'm going to need a, import config request. I will talk about each of these as we go along. Now, this one is just our root object. And this is the one that we obviously are creating a tenant under. So I'm just going to go ahead and say root is, root, right? Like this. And then I can now create a new, can now create a new tenant. So I'm going to call this FV tenant. I'm trying to be consistent with the, with the stuff that is also in the, in the slides. So I have the managed object for the tenant, and I've imported that model up here, the tenant. I want this to be, the parent to be the root object. And I want this tenant to be the parent, to be PAW example. Let's call it PAW example one. And I also want an app profile that I'm going to be now part of my tenant. So now the parent is the tenant, right? And the name is going to be app one. And I can now run this, I can now run this, run this code. create, right? See, we don't get any errors. And if I now go here and I'm going to search for PAW, no matching objects are found. Why is that? Because we have now created locally the objects and how we want them to look like, right? We have specified the name, we have specified the application profile and all of that below it, right? We have basically specified the structure, but we have not yet sent a configuration request, right? The same way that in the get example here, we are sending a query, we can also send a configuration request, which is then a request to change something within the APIC. So we can go ahead and say, CFG request is config request. So this is the last object that I imported here. Leave that and then say, CFG request.addMO. In this case, this is going to be our tenant. And then I can say, CFG request.commit. No, sorry. I can go ahead and say, MOdir.commit. So this is on our directory object. I can now say, run this configuration request, right? Run whatever is part here. And you see, I'm only passing the tenant. I'm not passing the application profile because the application profile is a child of the tenant. And that way it will be part of our request. So I can now go ahead. You can now go ahead and run the script again. Now we go here again. You see, PIAW example one has been created. And if I go into application profiles, there we go, app one. And of course, this is just a toy example, right? We would probably want to do a bit more advanced things, but, you see now you can, with these models and with Cobra, you can pretty much do all the things that you want to do right here and automate this creation workflow, for example. And of course, in a real world environment, you would probably add a few more things. I don't know, add a VRF, add policies, add whatever you really have here as part of this. Now we've seen Cobra and we've seen the ideas behind them. As I said, all the code is also here. But before continuing with what we can do with this and look at a few different examples, a few different use cases that have been built by our SEs, are there any questions? There's one interesting question from Andy, mentioning that a friend uses PI ACI instead of Cobra. So he would like to know how does it compare? I don't have never heard of that. Is that a? Is that a community project? Maybe you can share my email address and I would be really happy to learn more and see that. Like if you look, for example, on code exchange or automation exchange and you type in ACI, you will find a lot of people that have built stuff around ACI that you can use to get inspiration or maybe see if there's something that someone has already built your workflow. But yeah, but Cobra is the stuff that we ship with the APIC and that we have things like learning labs for and that we have these kinds of things for. Thank you. So let's have a look at some use cases, right? Let's have a look at what we can do. And the first one is a use case built by Stuart Traynor. He's one of our SEs from Scotland. And what he had as a business problem is that there is a lot of different touch points with applications, right? You have ACI, you might have Intrasite and you have maybe your own metrics tools and you get into that swivel chair mentality where you have 15 different screens, which looks cool, but also can be a bit intimidating, I would say with 15 different dashboards open that all show metrics and you need to cross correlate that metric about your application being slow to that metric about congestion in your switches, right? And do that swivel chair maintenance. And what he basically built was, or what he proposes to build is he says, hey, we can have a simple Python app that collects data, not only the data, but also the data not only from ACI, but also from ACI, Intrasite, AppDynamics, whatever you have really, cloud providers if you're in a hybrid environment, whatever data you have and whatever API available data you have, store all of that in InfluxDB and then use Grafana to build a custom dashboard that really shows exactly your metrics, right? For example, as I said, like congestion and throughput metrics combined with your app performance, with your average app performance, if that's something, you can actually build a custom dashboard and that's something you are measuring. And this of course helps both the infrastructure people as well as the application stakeholders, because they can more easily understand the impact of something on their application, of something in the infrastructure on their application. And there's a little demo video as well we can see here. So this is Stuart building out in Grafana, building out the interface. You can see, and he can add all of the different metrics that he has been parsing from the API, from the ASIC API. There was one of these gawks was the application request time, things like that, really whatever he has and he can then chart them out and build a custom, fairly quickly build a custom build interface. And of course, this is all based on the monitoring information that we are pulling into the InfluxDB from the ACI API, from the APIC APIs. Another one that we have is day two operations. This one is built by Russ Whittier, who's our probability lead for data center in EMER. And what he says is that this was a service provider use case, a customer that wanted to have visibility into dependencies with VLAN pools and within that ACI policy model, right? He wanted to have like a nice graphical implementation or nice graphical explorable thing where he can see these, these codependencies and in the ACI GUI itself, this can be hard to correlate, but we can build that custom, right? We can build that ourself. So the, this is a GoJS or a Python Flask app that pulls the API, retrieve all the policy objects and then visualizes them in like an, in a network graph. So again, also a bit of a monitoring use case, but more related to adding, to adding as existing or adding additional visibility, not like the Grafana dashboard example. Leo, are you going to say something? Yeah, I just wanted to mention, if there is something that we can use to export it into Prometheus, you know, because we are talking about how to make it available for Grafana, going through Influx TV. There's something similar that we can use with Prometheus. You caught me. Yeah, you can also do that with, I mean, what you're pushing your data into depends on what you wanna do, right? Like you can also push it into in Prometheus instead of influx DB. You can also push it in Elastic or something like that if that's what you're using, absolutely. Okay, thank you. So let's have a look here at the example for the tenant. And this example, by the way, is available. This was built by our GVE team. And together with Russ and the video is, I'm going to skip a bit through the video because it's fairly long. And he shows like all the stuff in the, you see the VLAN pools in ACI. And let me skip to, and this is all installed and all set up. Yeah, there we go. Now we're going to the configuration. We're going here to the visualizer and you see we're pulling the different pools here from the API. So we can see the API already. And then you can go in here and say, this is the pool that he wants. And now it's fetching the data and also rendering the graph. And now you can see here, this is like a scrollable, a zoomable and a modifiable. And you can even see like highlights here where, okay, this is connected to this and the paths are highlighted in that graph, right? Like a very, very convenient way to get like an overview of all of that information that is not naturally available or natively available. And then, so we had seen two monitoring use cases, one being, I would say, I would call it a classical monitoring use case and the other one being a bit more in a visualization and the value at monitoring, right? The visualization of the graph, it's not just pouring out metrics, but it's a bit more, But I also want to show you a automation use case, again from Ross. And in this case, this was a UK financial institution where they had a third party company that modified their connectivity rules. So they would have an end user do a connectivity request, right? To the ITSM, to ServiceNow, right? Requesting that the rule would be changed and that some access would be allowed, then you'd have an approval process. This is just a security application. approvals, first and second approver. And then that provisioning request would be forwarded to an outsourced provisioning company that would go ahead and then do the modification here on the two hosts. Of course, this took quite a long time. You know, there's a few manual steps, a few of manual steps that you cannot get around, like the approval process, right? That is just policy. But what they did, what they ended up doing is, yeah, 12 weeks from the initial request to deployment, what they ended up doing is they did an automation with Ansible and Ansible Power. And as I said, this is just the tool here, right? You could also do the same workflow with a script written with Cobra. Maybe you can do it with ACI Toolkit, or you could probably do it with Terraform, right? It's really just a tool that you're trying to use. So the flow that they ended up doing was they had ServiceNow do a request, and then Ansible would, based on the request in ServiceNow, be used to still have that approval process, right? Still waiting for the first and second approval in ServiceNow. But then as soon as that approval was kicked off, Ansible, where the script would go ahead and create the filters, create the subjects, create just whatever we wanted in terms of the change request, and send that to ACI. And that way, the time went down from 12 weeks between requesting, and having the change applied to, as soon as the approvals were there, right? It's like minutes, less than minutes. And if you think about the beginning of this presentation, we talked about making the data center more cloud-like, these are exactly the kind of things that developers really dislike about sometimes, about these processes and how you can make them more convenient, make them faster, right? Going down from waiting 12 weeks for some sort of change can be really, really frustrating. And using this automation, you can make it faster, right? And make that much more convenient. I already said there's a few useful links in here, the learning labs, the SDK files, the corporate documentation. And with that, I will share that presentation and I will add two more useful links that we just talked about. And with that, thank you very much for your attention. If there are any questions, please go ahead. I think we are good. No questions pending. All right, that's cool. Then next week, we are going to do the second part of our data center automation series, where we're going to talk about intersite and intersite automation. And I hope to see you there. And if you have any questions in the meantime, I think Julio has posted my handle in the chat. Please feel free to shoot me an email. And yeah, thank you very much for attending.