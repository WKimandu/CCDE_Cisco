Goodnight. Welcome, baby. It's already eleven. OK. I have sent my uh the documents for Kiwuma to Gofu and the guy was taking the. So the man who called me when? When we were in the restaurant. Oh, that was the contractor. So I sent him all the documents. And I told that golf also. From that man. Yes, yeah, yeah. So in East after he advised me no, don't, don't change the the. Keep it as you own it, yeah? Yeah, I know. I will go down in fact. Alright, OK. Hello, good evening 

I am a software engineer with a passion for building scalable and efficient systems. I am currently working on a project to build a knowledge base for CCDE and Cisco ACI.

I am using LlamaIndex to build the knowledge base.

 want us to be consequent. And diligence in how we plan. To build the AI. Frameworks. For CCDE and Cisco ACI. Training. This means that also we need to have. Deep dives on. Cisco data center. Automation and Devops. Meaning we need to understand CICD pipelines. The volumetrics. Gate operations. And their all their best practices involved in this. Occasionally we will double in Terraform. Ansible. And Piven. And Python. We have a lot of documents that we need to process. So that we can create a knowledge base for our retrieval augmented generation. It is then used for other downstream tasks. Like summarization, Q and A. 'cause development. Test quizzes and exams with detailed feedback and. Source material references. An online chat boxes on the subjects that we are going to encounter in this material. Chat OPS chat boxes. Now I have selected to use Lambda index. LAMA index allows me to on board. To ingest. Documents of all kinds. Extract them. Multimodal, so images, text. Any other form of, including formatting. We also have transCripts. From videos that I've used to whisper. The Python mode used to extract and store as TSV's or txt,vtt, you name it. What I then just realized is this. Every document that I have. Is forecast on a very specific area of study, subject, topic. And that topic aligns with the curriculum details that we have. And so we not only have to. Classify the documents, raw documents, Powerpoints, PDFS, Word document, markdown files, text files, TV. Transcript files. Then create. Rags for each of these, so by domain by topic. And then create the vector databases. And then somehow they have to be interlinked. He will explain to me how we do that. Question number one. I have multiple subjects. They are in a curriculum. That curriculum is. Serially developed from basic to advanced. We also have curriculum documents that tell us tells us that a particular kind of exam or module or test is forecast on this test text. But at the end of the day, if you want to become a network designer or you want to do these exams, you will have gone through all the material and therefore you will have to answer questions. From anywhere within the material. So with that in mind. We need to say how do we? Take. The documents as they are. Ingest I'm using llamaindex loaders.
 then we will use langchain and other frameworks to create agentic training and design implementation artifacts like , templates. Primers, ground truths, Prompts management, finetuning
 extraction jobs will be multi-modal, text, images, audio, video, and then we will use langchain and other frameworks to create agentic training and design implementation artifacts like , templates. Primers, ground truths, Prompts management, finetuning
